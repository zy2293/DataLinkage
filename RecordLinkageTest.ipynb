{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# validate pairs by other attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validate(predictions, address_locu, address_foursquare, attr):\n",
    "    locu_y = address_locu[\"id\"]\n",
    "    foursquare_y = address_foursquare[\"id\"]\n",
    "    count = 0\n",
    "    matched = {}\n",
    "    Nmatched = {}\n",
    "    locu = []\n",
    "    fq = []\n",
    "    \n",
    "    for key, value in predictions.items():\n",
    "        locu_key = address_locu.index[locu_y == key].tolist()\n",
    "        fs_key = address_foursquare.index[foursquare_y == value].tolist()\n",
    "        \n",
    "        if (address_locu[attr][locu_key].tolist()) == (address_foursquare[attr][fs_key].tolist()):\n",
    "            matched[key] = value\n",
    "            count += 1\n",
    "            locu.append(key)\n",
    "            fq.append(value)\n",
    "        else:\n",
    "            locu_value = address_locu[\"phone\"][locu_key].tolist()\n",
    "            fs_value = address_foursquare[\"phone\"][fs_key].tolist()\n",
    "            if locu_value == fs_value:\n",
    "                matched[key] = value\n",
    "                count += 1\n",
    "                locu.append(key)\n",
    "                fq.append(value)\n",
    "                \n",
    "            else:\n",
    "                locu_zipcode= address_locu[\"latitude\"][locu_key].tolist()\n",
    "                fq_zipcode= address_foursquare[\"latitude\"][fs_key].tolist()\n",
    "                if locu_zipcode == fq_zipcode:\n",
    "                    \n",
    "                    matched[key] = value\n",
    "                    count += 1\n",
    "                    locu.append(key)\n",
    "                    fq.append(value)\n",
    "                else:\n",
    "                    Nmatched[key] = value\n",
    "            \n",
    "    print (\"validated \", count)\n",
    "    #print (len(matched.keys()))\n",
    "    return matched, Nmatched, locu, fq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# parse address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import usaddress\n",
    "def AddressParse(df, attrs):\n",
    "    \n",
    "    df1 = df[df[attrs].apply(lambda x: len(x) != 0)]\n",
    "    index = df1.index.tolist()\n",
    "    for ind in index:\n",
    "        try:\n",
    "            tags = dict(usaddress.tag(df[attrs][ind])[0])\n",
    "            key = list(tags.keys())\n",
    "            if 'AddressNumber' in key:\n",
    "                df['AddressNumber'][ind] = tags['AddressNumber']\n",
    "                \n",
    "            if 'StreetName' in key:\n",
    "                df['StreetName'][ind] = tags['StreetName']\n",
    "                \n",
    "            if 'StreetNamePreDirectional' in key:\n",
    "                df['StreetNamePreDirectional'][ind] = tags['StreetNamePreDirectional']\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# address, phone normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize two dataframe\n",
    "def Normalize(df):\n",
    "    df[\"phone\"].replace(np.nan, '', inplace = True)\n",
    "    df[\"phone\"] = df[\"phone\"].apply(lambda x: x.replace('-', '').replace(')', '').replace('(', '').replace(' ', ''))\n",
    "    df['StreetNamePreDirectional'] = df['StreetNamePreDirectional'].apply(lambda x: x.replace('W.', 'West').replace('E.', 'East').replace('N.', 'North').replace('S.','South'))\n",
    "    \n",
    "    print (\"finish normalization\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# URL parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse\n",
    "def UrlParse(df, attrs):\n",
    "    df1 = df[df[attrs].apply(lambda x: len(x) != 0)]\n",
    "    index = df1.index.tolist()\n",
    "    for ind in index:\n",
    "        o = urlparse(df[attrs][ind])\n",
    "        df[\"url\"][ind] = o.netloc\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generateCluster(fit_y, predict_y):\n",
    "    clusters = {}\n",
    "    records = fit_y.shape[0]\n",
    "    print (records)\n",
    "\n",
    "    for ind in range(records):\n",
    "        key = fit_y[ind]\n",
    "        if key in clusters.keys():\n",
    "            clusters[key].append(predict_y[ind])\n",
    "            print (\"same map\")\n",
    "        else:\n",
    "            clusters[key] = predict_y[ind]\n",
    "    \n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(testdf):\n",
    "    # parse street address to AddressNumber, StreetName, StreetNamePreDirectional\n",
    "    testdf['AddressNumber'] = ''\n",
    "    testdf['StreetName'] = ''\n",
    "    testdf['StreetNamePreDirectional'] = ''\n",
    "    testdf = AddressParse(testdf, \"street_address\")\n",
    "    \n",
    "    # Normalization\n",
    "    testdf = Normalize(testdf)\n",
    "    \n",
    "    # Urlparse\n",
    "    testdf[\"url\"] = ''\n",
    "    testdf = UrlParse(testdf, \"website\")\n",
    "    \n",
    "    print (\"finish preprocessing\")\n",
    "    return testdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN\n",
    "# No record duplicate in each file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "def train_knn(model, address_foursquare, address_locu):\n",
    "    select_col = [\"latitude\", \"longitude\"]#, \"postal_code\"]\n",
    "    foursquareTrain = address_foursquare[select_col]\n",
    "    locuTrain = address_locu[select_col]\n",
    "    \n",
    "    foursquare_y = address_foursquare[\"id\"]\n",
    "    locu_y = address_locu[\"id\"]\n",
    "\n",
    "    #foursquareTrain[\"postal_code\"] = pd.to_numeric(foursquareTrain[\"postal_code\"])\n",
    "    foursquareTrain.fillna(0, inplace = True)\n",
    "    #locuTrain[\"postal_code\"] = pd.to_numeric(locuTrain[\"postal_code\"])\n",
    "    locuTrain.fillna(0, inplace = True)\n",
    "    \n",
    "    if model == \"svc\":\n",
    "        scaler = StandardScaler()\n",
    "        foursquareTrain= scaler.fit_transform(foursquareTrain)\n",
    "        locuTrain = scaler.transform(locuTrain)\n",
    "        clf = svm.SVC(decision_function_shape='ovo')\n",
    "    elif model == \"rf\":\n",
    "        #clf = RandomForestClassifier(max_leaf_nodes=None, random_state=0)\n",
    "        clf = DecisionTreeClassifier(max_leaf_nodes=None, random_state=0)\n",
    "        #clf.estimators = 20\n",
    "    elif model == \"knn\":\n",
    "        clf = KNeighborsClassifier(n_neighbors=1)\n",
    "    \n",
    "\n",
    "    clf.fit(foursquareTrain,foursquare_y)\n",
    "    locu_predict = clf.predict(locuTrain)\n",
    "\n",
    "    predictions = dict(zip(locu_y, locu_predict))\n",
    "\n",
    "    knn_predictions, Nvalidated, locu, fq = validate(predictions, address_locu, address_foursquare, \"name\")\n",
    "    \n",
    "    # delete ones already matched\n",
    "    train_foursquare = address_foursquare[~address_foursquare[\"id\"].isin(fq)]\n",
    "    train_locu = address_locu[~address_locu[\"id\"].isin(locu)]\n",
    "    \n",
    "    return knn_predictions, Nvalidated, train_foursquare, train_locu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def StringCompare(address_foursquare, address_locu, attrs):\n",
    "    foursquare_Address = address_foursquare[address_foursquare[attrs].apply(lambda x: len(x) != 0)]\n",
    "\n",
    "    foursquareAddress = foursquare_Address[attrs] # 185\n",
    "    foursquareIndex = foursquareAddress.index.tolist()\n",
    "    \n",
    "    locu_Address = address_locu[address_locu[attrs].apply(lambda x: len(x) != 0)]\n",
    "    locuAddress = locu_Address[attrs] # 260\n",
    "    locuIndex = locuAddress.index.tolist()\n",
    "    \n",
    "    candidate_links = pd.MultiIndex.from_product([locuIndex, foursquareIndex],names=['locu', 'foursquare'])\n",
    "    \n",
    "    return locuIndex, foursquareIndex, locu_Address, foursquare_Address, candidate_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import recordlinkage\n",
    "def Levenshtein(candidate_links, locuIndex, locu_Address, foursquare_Address, attrs):\n",
    "    comp = recordlinkage.Compare()\n",
    "    for att in attrs:\n",
    "        comp.string(att, att, method='damerau_levenshtein')\n",
    "    \n",
    "        \n",
    "    levenDist = comp.compute(candidate_links, locu_Address, foursquare_Address)\n",
    "    \n",
    "    records = locu_Address.shape[0]\n",
    "    pairs = {}\n",
    "    for index in locuIndex:\n",
    "        level = levenDist.loc[levenDist.index.get_level_values(\"locu\") == index].reset_index()\n",
    "        level['distance'] = level[0]**2 + level[1]**2 + level[2]**2\n",
    "        co = np.argmax(level['distance'].tolist())\n",
    "        if level['distance'].tolist()[co] > 2.5:\n",
    "            match_index = level['foursquare'][co]\n",
    "            if locu_Address[\"name\"][index] != \"Lizzie's Restaurant\":\n",
    "                pairs[locu_Address[\"id\"][index]] = foursquare_Address[\"id\"][match_index]\n",
    "                print (locu_Address[\"street_address\"][index], '$$$', foursquare_Address['street_address'][match_index], level['distance'].tolist()[co])\n",
    "                print (locu_Address[\"name\"][index], '$$$', foursquare_Address['name'][match_index], level['distance'].tolist()[co])\n",
    "                \n",
    "    return pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AddressCompare(knn_foursquare, knn_locu, attrs):\n",
    "    locuIndex, foursquareIndex, locu_Address, foursquare_Address, candidate_links = StringCompare(knn_foursquare, knn_locu, attrs)\n",
    "    attributes = ['AddressNumber', 'StreetName', 'StreetNamePreDirectional']\n",
    "    levenshtainpairs = Levenshtein(candidate_links, locuIndex, locu_Address, foursquare_Address, attributes)\n",
    "\n",
    "    matched, Nmatched, locu, fq = validate(levenshtainpairs, knn_locu, knn_foursquare, \"name\")\n",
    "    left_foursquare = knn_foursquare[~knn_foursquare[\"id\"].isin(fq)]\n",
    "    left_locu = knn_locu[~knn_locu[\"id\"].isin(locu)]\n",
    "    return matched, Nmatched, left_foursquare, left_locu, levenshtainpairs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare phone/name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def PhoneCompare(train_foursquare, train_locu, attribute):\n",
    "    notnull_foursquare = train_foursquare[train_foursquare[attribute] != ''] \n",
    "    notnull_locu = train_locu[train_locu[attribute] != '']\n",
    "    \n",
    "    columns = [\"id\", attribute]\n",
    "    compare_foursquare = notnull_foursquare[columns]\n",
    "    compare_locu = notnull_locu[columns]\n",
    "    \n",
    "    # merge attribute\n",
    "    compare_result = compare_foursquare.merge(compare_locu, left_on = compare_foursquare[attribute], right_on=compare_locu[attribute], how = \"inner\")\n",
    "    \n",
    "    compare_cols = [\"id_x\", \"id_y\"] # x: foursquare, y: locu\n",
    "    predict = compare_result[compare_cols]\n",
    "    predict = predict.set_index(\"id_y\")\n",
    "    predict = predict.to_dict()\n",
    "    compare_predict = predict[\"id_x\"]\n",
    "    \n",
    "    matched, Nmatched, locu, fq = validate(compare_predict, train_locu, train_foursquare, \"name\")\n",
    "    \n",
    "    train_foursquare = train_foursquare[~train_foursquare[\"id\"].isin(fq)]\n",
    "    train_locu = train_locu[~train_locu[\"id\"].isin(locu)]\n",
    "    \n",
    "    return matched, Nmatched, train_foursquare, train_locu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def urlLevenshtein(candidate_links, locuIndex, locu_Address, foursquare_Address, attrs):\n",
    "    comp = recordlinkage.Compare()\n",
    "    comp.string(attrs, attrs, method='damerau_levenshtein')\n",
    "    levenDist = comp.compute(candidate_links, locu_Address, foursquare_Address)\n",
    "    \n",
    "    records = locu_Address.shape[0]\n",
    "    pairs = {}\n",
    "    for index in locuIndex:\n",
    "        level = levenDist.loc[levenDist.index.get_level_values(\"locu\") == index].reset_index()\n",
    "        co = np.argmax(level[0].tolist())\n",
    "        match_index = level['foursquare'][co]\n",
    "        if level[0].tolist()[co] > 0.8 and (locu_Address[\"postal_code\"][index] == foursquare_Address['postal_code'][match_index]):\n",
    "            pairs[locu_Address[\"id\"][index]] = foursquare_Address[\"id\"][match_index]\n",
    "            print (locu_Address[\"name\"][index], '$$$', foursquare_Address['name'][match_index], level[0].tolist()[co])\n",
    "            print (locu_Address[\"postal_code\"][index], '$$$', foursquare_Address['postal_code'][match_index], level[0].tolist()[co])\n",
    "    return pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def UrlCompare(name_foursquare, name_locu, attrs):\n",
    "    locuIndex, foursquareIndex, locu_Address, foursquare_Address, candidate_links = StringCompare(name_foursquare, name_locu, attrs)\n",
    "    urlpairs = urlLevenshtein(candidate_links, locuIndex, locu_Address, foursquare_Address, attrs)    \n",
    "    return urlpairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LEFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "\n",
    "def remove_accents(input_str):\n",
    "    nfkd_form = unicodedata.normalize('NFKD', input_str)\n",
    "    only_ascii = nfkd_form.encode('ASCII', 'ignore')\n",
    "    return str(only_ascii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nameLevenshtein(candidate_links, locuIndex, locu_Address, foursquare_Address, attrs):\n",
    "    comp = recordlinkage.Compare()\n",
    "    comp.string(attrs, attrs, method='damerau_levenshtein')\n",
    "    levenDist = comp.compute(candidate_links, locu_Address, foursquare_Address)\n",
    "    \n",
    "    records = locu_Address.shape[0]\n",
    "    pairs = {}\n",
    "    for index in locuIndex:\n",
    "        level = levenDist.loc[levenDist.index.get_level_values(\"locu\") == index].reset_index()\n",
    "        co = np.argmax(level[0].tolist())\n",
    "        match_index = level['foursquare'][co]\n",
    "        locu_add = locu_Address[\"street_address\"][index]\n",
    "        foursquare_add = foursquare_Address[\"street_address\"][match_index]\n",
    "        locu_zip = locu_Address[\"postal_code\"][index]\n",
    "        foursquare_zip = foursquare_Address[\"postal_code\"][match_index]\n",
    "        \n",
    "        log1 = len(locu_add) == 0 or len(foursquare_add)==0 # one of addresses missing\n",
    "        log2 = locu_zip == foursquare_zip # same zip code\n",
    "        log3 = ((len(locu_zip)==0) or len(foursquare_zip) ==0) # one of zipcodes missing\n",
    "        \n",
    "        if level[0].tolist()[co] > 0.9:\n",
    "            pairs[locu_Address[\"id\"][index]] = foursquare_Address[\"id\"][match_index]\n",
    "            print (locu_Address[\"name\"][index], '$$$', foursquare_Address['name'][match_index], level[0].tolist()[co])\n",
    "            print (locu_Address[\"phone\"][index], '$$$', foursquare_Address['phone'][match_index], level[0].tolist()[co])\n",
    "        elif level[0].tolist()[co] > 0.7 and log1 and (log2 or log3) :\n",
    "            print (locu_Address[\"name\"][index], '$$$', foursquare_Address['name'][match_index], level[0].tolist()[co])\n",
    "            print (locu_Address[\"postal_code\"][index], '$$$', foursquare_Address['postal_code'][match_index], level[0].tolist()[co])\n",
    "            pairs[locu_Address[\"id\"][index]] = foursquare_Address[\"id\"][match_index]\n",
    "    return pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NameCompare(name_foursquare, name_locu, attrs):\n",
    "    name_foursquare[attrs] = name_foursquare[attrs].apply(lambda x: remove_accents(x))\n",
    "    name_locu[attrs] = name_locu[attrs].apply(lambda x: remove_accents(x))\n",
    "\n",
    "    locuIndex, foursquareIndex, locu_Address, foursquare_Address, candidate_links = StringCompare(name_foursquare, name_locu, attrs)\n",
    "    namepairs = nameLevenshtein(candidate_links, locuIndex, locu_Address, foursquare_Address, attrs)\n",
    "    \n",
    "    return namepairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test dataset left untouched\n",
    "test_foursquare = pd.read_json(\"online_competition/foursquare_test.json\")\n",
    "test_locu = pd.read_json(\"online_competition/locu_test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train dataset\n",
    "train_foursquare = pd.read_json(\"train/foursquare_train.json\")\n",
    "train_locu = pd.read_json(\"train/locu_train.json\")\n",
    "match = pd.read_csv(\"train/matches_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PipeLine(test_locu, test_foursquare):\n",
    "    locu = preprocess(test_locu)\n",
    "    foursquare = preprocess(test_foursquare)\n",
    "    # rf\n",
    "    rf_validated, rf_Nvalidated, rf_foursquare, rf_locu= train_knn(\"rf\",foursquare, locu)\n",
    "    # SVC\n",
    "    knn_validated, knn_Nvalidated, knn_foursquare, knn_locu= train_knn(\"svc\",rf_foursquare, rf_locu)\n",
    "    # Compare Address after KNN\n",
    "    address_matched, address_Nmatched, left_foursquare, left_locu, addresspairs = AddressCompare(knn_foursquare, knn_locu, attrs = \"street_address\")\n",
    "    # Compare Phone & Name after Address Compare\n",
    "    phone_matched, phone_Nmatched, phone_foursquare, phone_locu = PhoneCompare(left_foursquare, left_locu, \"phone\")\n",
    "    name_matched, name_Nmatched, name_foursquare, name_locu = PhoneCompare(left_foursquare, left_locu,\"name\")\n",
    "    # Compare url after Name Compare\n",
    "    urlnamepairs = UrlCompare(name_foursquare, name_locu, attrs = \"url\")\n",
    "    #urlphonepairs = UrlCompare(phone_foursquare, phone_locu, attrs = \"url\")\n",
    "    # Compare Name after Name Compare\n",
    "    namepairs = NameCompare(name_foursquare, name_locu, attrs = \"name\")\n",
    "    #namephonepairs = NameCompare(phone_foursquare, phone_locu, attrs = \"name\")\n",
    "    \n",
    "    return rf_validated, knn_validated, addresspairs, phone_matched, name_matched, urlnamepairs,  namepairs\n",
    "\n",
    "#knn_validated, addresspairs, phone_matched, name_matched, urlpairs, namepairs = PipeLine(test_locu, test_foursquare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final(locu, foursquare):\n",
    "    rf_validated, knn_validated, addresspairs, phone_matched, name_matched, urlpairs,  namepairs = PipeLine(locu, foursquare)\n",
    "    \n",
    "    result = addresspairs.copy()\n",
    "    print (len(result.keys()))\n",
    "    result.update(rf_validated)\n",
    "    print (len(result.keys()))\n",
    "    result.update(knn_validated)\n",
    "    print (len(result.keys()))\n",
    "\n",
    "    result.update(name_matched)\n",
    "    print (len(result.keys()))\n",
    "\n",
    "    result.update(phone_matched)\n",
    "    print (len(result.keys()))\n",
    "\n",
    "    result.update(namepairs)\n",
    "    print (len(result.keys()))\n",
    "    \n",
    "    #result.update(namephonepairs)\n",
    "    #print (len(result.keys()))\n",
    "\n",
    "    result.update(urlpairs)\n",
    "    print (len(result.keys()))\n",
    "    \n",
    "    #result.update(namephonepairs)\n",
    "    #print (len(result.keys()))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish normalization\n",
      "finish preprocessing\n",
      "finish normalization\n",
      "finish preprocessing\n",
      "validated  184\n",
      "validated  40\n",
      "321 East Houston St. $$$ 321 E. Houston St. 3.0\n",
      "El Maguey y la Tuna $$$ El Maguey y La Tuna 3.0\n",
      "356 W. 58th St. $$$ 356 W. 58th St. 3.0\n",
      "Hudson Common @ the Hudson $$$ The Library at Hudson Hotel 3.0\n",
      "40 West 8th St. $$$ 40 W. 8th St. 3.0\n",
      "Curry Kitchen $$$ Curry Kitchen 3.0\n",
      "424 East 9th St. $$$ 424 E. 9th St. 3.0\n",
      "Exchange Alley $$$ Exchange Alley 3.0\n",
      "315 West 36th St. $$$ 315 W. 36th St. 3.0\n",
      "Staghorn Steakhouse $$$ staghorn steakhouse 3.0\n",
      "231 E. 50th St. $$$ 231 E. 50th St. 3.0\n",
      "DEGREZIA RESTAURANT $$$ Ristorante DeGrezia 3.0\n",
      "validated  3\n",
      "validated  4\n",
      "validated  3\n",
      "Baskin Robbins $$$ Baskin-Robbins 1.0\n",
      "10007 $$$ 10007 1.0\n",
      "DEGREZIA RESTAURANT $$$ Ristorante DeGrezia 0.8461538461538461\n",
      "10022 $$$ 10022 0.8461538461538461\n",
      "b'El Maguey y la Tuna' $$$ b'El Maguey y La Tuna' 0.9545454545454546\n",
      "2124733919 $$$ 2124733744 0.9545454545454546\n",
      "b'Baskin Robbins' $$$ b'Baskin-Robbins' 0.9411764705882353\n",
      "2125777550 $$$ 2125777550 0.9411764705882353\n",
      "b'Hotel Gansevoort' $$$ b'55 Gansevoort' 0.736842105263158\n",
      "10014 $$$  0.736842105263158\n",
      "b'A Saffron Thread Fresh Indian' $$$ b'Saffron Fresh Indian' 0.71875\n",
      "10007 $$$ 10007 0.71875\n",
      "b'ABC Chinese Restaurant' $$$ b'Chinese Restaurant' 0.84\n",
      "10013 $$$ 10013 0.84\n",
      "6\n",
      "190\n",
      "230\n",
      "233\n",
      "235\n",
      "238\n",
      "238\n"
     ]
    }
   ],
   "source": [
    "result = final(test_locu, test_foursquare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame.from_dict(result, orient = 'index')\n",
    "predictions.reset_index(inplace = True)\n",
    "predictions.columns = [\"locu_id\", \"foursquare_id\"]\n",
    "predictions.to_csv(\"train_predictions.csv\", encoding='utf-8', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test generalization\n",
    "###### knn: precision: 0.98, recall: 0.9527777777777777, F1-score: 0.9661971830985915\n",
    "###### svc: precision: 0.98, recall: 0.9527777777777777, F1-score: 0.9661971830985915"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# match dictionary\n",
    "def match_to_dict(match):\n",
    "    match = match.set_index(\"locu_id\")\n",
    "    match = match.to_dict()\n",
    "    \n",
    "    compare_match = match[\"foursquare_id\"]\n",
    "    return compare_match\n",
    "match_dict = match_to_dict(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def matchRecords(match_dict, compare_predict):\n",
    "    matched = {}\n",
    "    Nmatched = {}\n",
    "    match_count = 0\n",
    "    Nmatch_count = 0\n",
    "    keylist = match_dict.keys()\n",
    "    locu = []\n",
    "    fq = []\n",
    "    \n",
    "    for key, value in compare_predict.items():\n",
    "        if key in keylist and match_dict[key] == value:\n",
    "            match_count +=1          \n",
    "            matched[key] = value\n",
    "            locu.append(key)\n",
    "            fq.append(value)\n",
    "        else:\n",
    "            Nmatch_count += 1\n",
    "            Nmatched[key] = value\n",
    "            \n",
    "    precision = match_count*1.0 /(len(compare_predict.keys()))\n",
    "    recall = match_count*1.0 /(len(keylist))\n",
    "    \n",
    "    F1 = 2*precision*recall /(precision + recall)\n",
    "    print (\"matched records: {}\".format(match_count))\n",
    "    print (\"not matched records: {}\".format(Nmatch_count))\n",
    "    \n",
    "    print (\"precision: {}, recall: {}, F1-score: {}\".format(precision, recall, F1))\n",
    "    return locu, fq, matched, Nmatched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish normalization\n",
      "finish preprocessing\n",
      "finish normalization\n",
      "finish preprocessing\n",
      "validated  260\n",
      "validated  70\n",
      "214 West 39th St. $$$ 214 W. 39th St. 3.0\n",
      "Enrico Ferezi Inc $$$ Enrico Ferezi 3.0\n",
      "127 W. 28th St. $$$ 127 W. 28th St. 3.0\n",
      "Blu NYC $$$ Blu NYC 3.0\n",
      "9 E. 18th St. $$$ 9 E. 18th St. 3.0\n",
      "Rosa Mexicano - Union Square $$$ Rosa Mexicano 3.0\n",
      "250 East Houston St. $$$ 250 E. Houston St. 3.0\n",
      "Dunkin' Donuts $$$ Dunkin Donuts 3.0\n",
      "684 Ave. Of The Americas $$$ 684 Ave. Of The Americas 3.0\n",
      "Starbucks $$$ Starbucks 3.0\n",
      "validated  3\n",
      "validated  9\n",
      "validated  7\n",
      "Azul Argentine Bistro $$$ Azul Bistro 1.0\n",
      "10002 $$$ 10002 1.0\n",
      "Rosa Mexicano - Union Square $$$ Rosa Mexicano 1.0\n",
      "10003 $$$ 10003 1.0\n",
      "Dunkin' Donuts $$$ Dunkin Donuts 1.0\n",
      "10025 $$$ 10025 1.0\n",
      "b'Little Town' $$$ b'Littletown' 0.8571428571428572\n",
      "10036 $$$  0.8571428571428572\n",
      "5\n",
      "265\n",
      "335\n",
      "342\n",
      "347\n",
      "348\n",
      "350\n"
     ]
    }
   ],
   "source": [
    "train_result = final(train_locu, train_foursquare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matched records: 343\n",
      "not matched records: 7\n",
      "precision: 0.98, recall: 0.9527777777777777, F1-score: 0.9661971830985915\n"
     ]
    }
   ],
   "source": [
    "matched_locu, matched_fq, matched, Nmatched = matchRecords(match_dict, train_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# knn: precision: 0.98, recall: 0.9527777777777777, F1-score: 0.9661971830985915"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
